import os
import requests
from flask import jsonify
from dotenv import load_dotenv
from openai import AzureOpenAI
import re
import json

load_dotenv()

# Extracts the prompts and sentences from the text generated by the LLM
def extract_prompts_and_sentences(text):
  # Split the text by 'PROMPT: ' to separate each prompt section
  parts = re.split(r'PROMPT: ', text)
  result = {}

  for index, part in enumerate(parts):
    # Skip empty strings due to splitting
    if part.strip() == "":
      continue

    # Extract the prompt within quotation marks
    prompt_match = re.search(r'"([^"]+)"', part)
    if not prompt_match:
      continue  # If there's no match, skip this part
    prompt = prompt_match.group(1)

    # Capture all text following the prompt up until the next 'PROMPT: ' or the end of the string
    sentences_match = part[prompt_match.end():].split('PROMPT: ')[0]
    sentences = sentences_match.strip().replace('\n', " ")  # Remove new lines and trim whitespace

    # Assign the prompt and its associated sentences to the result object
    result[index] = {'prompt': prompt, 'sentences': sentences}

  return result


# Function for generating an exercise. It appears that the Azure API is taking care of the asynchronous 
# nature of the calls so this function is synchronous.
def generate_exercise(req):

  # 
  text_endpoint = os.environ['AZURE_OPENAI_TEXTGPT_ENDPOINT']
  dalle_endpoint = os.environ['AZURE_OPENAI_DALLE_ENDPOINT']
  azure_api_key = os.environ['AZURE_OPENAI_KEY']
  
  body = req.json
  #print(body)
  difficulty = body['difficulty']
  exercise_number = body['exerciseNumber']
  selected_exercise_type = body['selectedExerciseType']
  selected_topic = body['selectedTopic']
  #print(f"Generating exercise for {selected_topic} with difficulty {difficulty} and exercise number {exercise_number}.")
  
  prompt = f'Compose a short, engaging story for a 7-year-old child with reading difficulties, centered around ${selected_topic}. The sentences should be simple, with clear and consistent structure. Ensure that the text is cohesive and forms an engaging narrative about ${selected_topic}, including aspects of their appearance, behavior, and environment. The story should be no longer than 200 words. Also give 3 DALLE prompts during the story that describes the text after it. Be consistent with the prompts and always describe the characters in the same way. Use Seed 42 for every single image.Always give the DALLE prompts with PROMPT:"<prompt>" and after each prompt give the story part that describes the prompt.'

  messages = [
    {
      "role": "system",
      "content": "You are a reading exercise generator, adapted for a 7 years old child with language impairments."
    },
    {
      "role": "user",
      "content": prompt
    }
  ]

  # Try to generate the exercise and prompts with gpt 4 in this try block.
  try:
    textClient = AzureOpenAI(
      api_version="2023-12-01-preview",  
      api_key=azure_api_key,  
      azure_endpoint=text_endpoint
    )

    response = textClient.chat.completions.create(
      model="gpt-4", # model = "deployment_name".
      messages=messages
    )

    #print(response.choices[0].message.content)
    chatGPTReply = response.choices[0].message.content

    prompts_and_sentences = extract_prompts_and_sentences(chatGPTReply)
    #print(prompts_and_sentences)
  
  except requests.RequestException as e:
    print(f"Error in generating the exercise and prompts: {e}")
    return jsonify({"error": "Internal Server Error"}), 500

  # Try to generate the images in this try block.
  try:
    # Diffenrent models have different endpoints
    dalleClient = AzureOpenAI(
      api_version="2023-12-01-preview",  
      api_key=azure_api_key,  
      azure_endpoint=dalle_endpoint
    )

    # Loop through the prompts and sentences and generate the images
    for key, value in prompts_and_sentences.items():
      print(key, value)
    
      result = dalleClient.images.generate(
        model= "dall-e-3", # the name of your DALL-E 3 deployment
        prompt= value['prompt'],
        n=1
      )

      #print(result)

      json_response = json.loads(result.model_dump_json())

      #print(json_response)

      image_url = json_response["data"][0]["url"]  # extract image URL from response

      #print(image_url)

      prompts_and_sentences[key]["url"] = image_url
  except Exception as e:
    print(f"Error in generating the images: {e}")
    return jsonify({"error": "Internal Server Error"}), 500

  # At the end, return the prompts, sentences and image urls
  print(prompts_and_sentences)
  return jsonify(prompts_and_sentences), 200